{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexisjkim/conformal_prediction_limitations/blob/main/Conformal_Prediction_Limitations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEsZ4OIF6J7L"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, ConcatDataset, random_split\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading data and splitting into train, calibration, test sets\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "# this dataset has the training data from MNIST; will be split into training and calibration sets\n",
        "mnist_train_set = torchvision.datasets.MNIST(root='./datasets/',\n",
        "                                           train=True,\n",
        "                                           transform=torchvision.transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "\n",
        "\n",
        "# this dataset has the test data from MNIST\n",
        "mnist_test_dataset = torchvision.datasets.MNIST(root='./datasets',\n",
        "                                          train=False,\n",
        "                                          transform=torchvision.transforms.ToTensor())\n",
        "\n",
        "\n",
        "train_percentage = 0.8 # this percentage of the training data set stays in the train set; the rest becomes part of the calibration set\n",
        "\n",
        "train_size = int(train_percentage *len(mnist_train_set))\n",
        "calibration_size = len(mnist_train_set) - train_size\n",
        "\n",
        "mnist_train_set, mnist_cal_set = random_split(mnist_train_set, [train_size, calibration_size])\n",
        "\n",
        "# Data loader\n",
        "mnist_train_loader = torch.utils.data.DataLoader(dataset=mnist_train_set,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True, drop_last=True)\n",
        "\n",
        "mnist_cal_loader = torch.utils.data.DataLoader(dataset=mnist_cal_set,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True, drop_last=True)\n",
        "\n",
        "# We use drop_last=True to avoid the case where the data / batch_size != int\n",
        "\n",
        "mnist_test_loader = torch.utils.data.DataLoader(dataset=mnist_test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "print(\"SIZES OF DATASETS: \")\n",
        "print(\"training set: \", len(mnist_train_loader.dataset))\n",
        "print(\"calibration set: \", len(mnist_cal_loader.dataset))\n",
        "print(\"testing set: \", len(mnist_test_loader.dataset))"
      ],
      "metadata": {
        "id": "mfNPe6Md7Cih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b79e19d-e993-4413-dd09-ca057d193344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./datasets/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 16170977.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./datasets/MNIST/raw/train-images-idx3-ubyte.gz to ./datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 496956.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./datasets/MNIST/raw/train-labels-idx1-ubyte.gz to ./datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 3868631.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to ./datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2185696.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./datasets/MNIST/raw\n",
            "\n",
            "SIZES OF DATASETS: \n",
            "training set:  48000\n",
            "calibration set:  12000\n",
            "testing set:  10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class for our neural network\n",
        "\n",
        "class TwoLayerNetPiped(torch.nn.Module):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
        "        member variables.\n",
        "        Parameters:\n",
        "            D_in - dimensions of inputs\n",
        "            H - number of hidden units per layer\n",
        "            D_out - dimensions of outputs\n",
        "        \"\"\"\n",
        "        # initialzing the parent object (important!)\n",
        "        super(TwoLayerNetPiped, self).__init__()\n",
        "        # Create a pipeline - a sequence of layers\n",
        "        self.pipe = torch.nn.Sequential(\n",
        "            torch.nn.Linear(D_in, H),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(H, D_out))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        In the forward function we accept a Tensor of input data and we must return\n",
        "        a Tensor of output data. We can use Modules defined in the constructor as\n",
        "        well as arbitrary operators on Tensors.\n",
        "        Parameters:\n",
        "            x - tensor of inputs (shape: [BATCH_SIZE, D_in])\n",
        "        \"\"\"\n",
        "        return self.pipe(x)"
      ],
      "metadata": {
        "id": "2Be4RGKH7exA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the model\n",
        "\n",
        "# hyper-parameters:\n",
        "num_epochs = 1\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Device configuration, as before\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# create model, send it to device\n",
        "model = TwoLayerNetPiped(D_in=28*28, H=256, D_out=10).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "QRyTuC717Dfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "\n",
        "\n",
        "model.train()  # training mode\n",
        "total_step = len(mnist_train_loader)\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(mnist_train_loader):\n",
        "        # each i is a batch of 128 samples\n",
        "        images = images.to(device).view(batch_size, -1)  # represent images as column vectors\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize - ALWAYS IN THIS ORDER!\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Time: {:.4f} secs'\n",
        "                   .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(), time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9plDgA17iaW",
        "outputId": "ef43a82b-2ed2-4f1e-dc26-87bd230aac45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Step [100/375], Loss: 0.3426, Time: 2.5092 secs\n",
            "Epoch [1/1], Step [200/375], Loss: 0.2782, Time: 4.7107 secs\n",
            "Epoch [1/1], Step [300/375], Loss: 0.2621, Time: 8.0662 secs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "\n",
        "def test_model(model, test_loader):\n",
        "\n",
        "  model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance), or use:\n",
        "  with torch.no_grad(): # \"don't keep track of the gradients\" ,can also use .detach()\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for images, labels in test_loader:\n",
        "          images = images.to(device).view(images.size(0), -1) #image.size(0) returns batch size\n",
        "          labels = labels.to(device)\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "      print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "\n",
        "test_model(model, mnist_test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDQWQtMs7kfL",
        "outputId": "a9120d7b-d462-4a7f-e109-f54a73419b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 93.72 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conformal prediction starts here"
      ],
      "metadata": {
        "id": "90lHwmd8fLIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calibration\n",
        "\n",
        "cal_probs = []\n",
        "cal_pred = []\n",
        "with torch.no_grad():\n",
        "  for images, labels in mnist_cal_loader:\n",
        "    images = images.to(device).view(images.size(0), -1)\n",
        "    outputs = model(images)\n",
        "    #OUTPUTS IS A TENSOR with values corresponding to each image's logits (raw unnormalized scores)\n",
        "    #softmax outputs a probabiity for each class\n",
        "    probabilities = torch.nn.functional.softmax(outputs, dim = 1) #1 corresponds to columns\n",
        "    #the prediction outputs the index of what it thinks the class is\n",
        "    #the omitted term is the value\n",
        "    _, predictions = torch.max(outputs.data, 1) #get the index of the highest output\n",
        "\n",
        "    # Append to lists\n",
        "    cal_pred.extend(predictions.cpu().numpy())\n",
        "    cal_probs.extend(probabilities.cpu().numpy())\n",
        "\n",
        "print(cal_probs[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGgyxMQzHDQl",
        "outputId": "67e93b7b-c8a1-4324-c531-57d5cd69b675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([4.9151044e-05, 1.7761309e-05, 1.0242654e-03, 2.2454487e-04,\n",
            "       2.8897154e-03, 1.2629440e-03, 7.0550470e-03, 2.6623131e-06,\n",
            "       9.5993304e-01, 2.7540868e-02], dtype=float32), array([1.9031499e-05, 2.1645799e-04, 6.4659311e-05, 2.7961194e-04,\n",
            "       1.1784593e-03, 3.0271948e-04, 1.8629456e-06, 9.7328293e-01,\n",
            "       5.4794981e-04, 2.4106339e-02], dtype=float32), array([3.2352060e-03, 5.3867490e-07, 5.9868897e-05, 1.9845819e-01,\n",
            "       1.0001037e-04, 2.2523753e-01, 4.8853335e-06, 2.6538512e-01,\n",
            "       4.0974751e-02, 2.6654395e-01], dtype=float32), array([1.15080955e-04, 4.93528560e-08, 5.29570534e-05, 3.33868340e-02,\n",
            "       2.45377964e-06, 9.64293301e-01, 1.86600751e-04, 1.27749360e-07,\n",
            "       1.95637438e-03, 6.32836600e-06], dtype=float32), array([3.7699076e-04, 8.8945382e-07, 1.6375295e-03, 1.2919343e-02,\n",
            "       1.3287524e-06, 9.5303333e-04, 6.0599483e-08, 9.7795630e-01,\n",
            "       9.3731076e-05, 6.0608303e-03], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cal_scores = []\n",
        "for prob, true_label in zip(cal_probs, cal_pred): #prob is the probability and true_label is index of pred\n",
        "  true_class_prob = prob[true_label] #the corresponding lists with their prob function getting the most predicted class\n",
        "  cal_scores.append(1 - true_class_prob) #s_i score\n",
        "\n",
        "cal_scores = np.array(cal_scores)\n",
        "sorted_scores = np.sort(cal_scores) #probabilities\n",
        "\n",
        "def get_quantile(scores, alpha):\n",
        "  n = 0\n",
        "  for images, labels in mnist_cal_loader:\n",
        "    n += labels.size(0)\n",
        "  q_level = math.ceil((1 - alpha) * (n + 1)) / n\n",
        "\n",
        "  print(f\"Adjusted quantile level: {q_level}\")\n",
        "  return np.percentile(scores, (1 - alpha) * 100)\n",
        "\n",
        "alpha = 0.05\n",
        "threshold = get_quantile(sorted_scores, alpha) #for the calibration set\n",
        "print(threshold)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQJrZ75ZYBRP",
        "outputId": "d1afd056-fa86-44ef-f846-8f82a2dd8296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjusted quantile level: 0.9501008064516129\n",
            "0.4504952162504196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#we know the conformal prediciton model takes in probabilities until it reaches the\n",
        "#the threshold q hat\n",
        "#the threshold is q hat (that quantile value)\n",
        "\n",
        "def conformal_prediction(probabilities, threshold):\n",
        "    predictions = []\n",
        "    for prob in probabilities:\n",
        "        sorted_indices = np.argsort(prob)[::-1]\n",
        "        total = 0.0\n",
        "        prediction = []\n",
        "        for i in sorted_indices:\n",
        "            total += prob[i]\n",
        "            prediction.append(i)\n",
        "            if total > 1 - threshold: #we do 1 - threshold because we want to observe the right side as we are adding in ascending order\n",
        "                break\n",
        "        predictions.append(prediction)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sPdmY-_OdGe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation\n",
        "def evaluate_and_print(observed_labels, conformal_prediction, predicted, start_row, end_row):\n",
        "  formatted_output = pd.DataFrame({\n",
        "    'observed labels': observed_labels,\n",
        "    'confromal prediction set': conformal_prediction,\n",
        "    'prediction': predicted\n",
        "  })\n",
        "\n",
        "\n",
        "  #evaluation metric\n",
        "  hits = 0\n",
        "  total = len(observed_labels)\n",
        "  for i in range(len(observed_labels)):\n",
        "    conf_pred_row = conformal_prediction[i]\n",
        "    observed = observed_labels[i]\n",
        "\n",
        "    if observed in conf_pred_row:\n",
        "      hits += 1\n",
        "\n",
        "  print(\"the prediction was in the set \", hits/total *100, \" percent of the time\")\n",
        "\n",
        "  print(formatted_output[start_row:end_row])\n"
      ],
      "metadata": {
        "id": "KfymFHAH2Y0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluating our testing data set\n",
        "\n",
        "observed_labels = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in mnist_test_loader:\n",
        "        observed_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "test_probs = []\n",
        "test_pred = []\n",
        "with torch.no_grad():\n",
        "    for images, _ in mnist_test_loader:\n",
        "        images = images.to(device).view(images.size(0), -1)\n",
        "        outputs = model(images)\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim = 1) #1 corresponds to columns\n",
        "        #the prediction outputs the index of what it thinks the class is\n",
        "        #the ommited term is the value\n",
        "        _, predictions = torch.max(outputs.data, 1) #get the index of the highest output\n",
        "        # Append to lists\n",
        "        test_pred.extend(predictions.cpu().numpy())\n",
        "        test_probs.extend(probabilities.cpu().numpy())\n",
        "\n",
        "conformal_predictions = conformal_prediction(test_probs, threshold)\n",
        "evaluate_and_print(observed_labels, conformal_predictions, test_pred, 300, 450)\n",
        "\n"
      ],
      "metadata": {
        "id": "WJ9v7D221CeL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc805388-e12e-41f8-b3a1-e5e198375a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the prediction was in the set  95.12  percent of the time\n",
            "     observed labels confromal prediction set  prediction\n",
            "300                4                      [6]           6\n",
            "301                7                      [7]           7\n",
            "302                1                      [1]           1\n",
            "303                2                      [2]           2\n",
            "304                4                      [4]           4\n",
            "..               ...                      ...         ...\n",
            "445                6                      [0]           0\n",
            "446                6                      [6]           6\n",
            "447                4                      [4]           4\n",
            "448                9                      [8]           8\n",
            "449                3                      [3]           3\n",
            "\n",
            "[150 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeating the experiment with test data that doesn't match the calibration set."
      ],
      "metadata": {
        "id": "Jvpco2U-XE1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adding gaussian blur with 5x5 kernel\n",
        "\n",
        "import cv2\n",
        "\n",
        "\n",
        "blur_loader = torch.utils.data.DataLoader(dataset=mnist_test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "def blur_images(image):\n",
        "  return torch.tensor(cv2.blur(images[i].numpy(), (30, 30)))\n",
        "\n",
        "\n",
        "\n",
        "observed_labels = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in blur_loader:\n",
        "        observed_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "#blur the images\n",
        "blurred_images = []\n",
        "blurred_labels = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in mnist_test_loader:\n",
        "        for i in range(len(images)):\n",
        "            blurred_image = blur_images(images[i])\n",
        "            blurred_images.append(blurred_image)\n",
        "            blurred_labels.append(labels[i])\n",
        "\n",
        "blurred_images = torch.stack(blurred_images)\n",
        "blurred_labels = torch.tensor(blurred_labels)\n",
        "\n",
        "\n",
        "blur_probs = []\n",
        "blur_pred = []\n",
        "\n",
        "# Flatten images for model input\n",
        "blurred_images = blurred_images.view(len(blurred_images), -1).to(device)\n",
        "\n",
        "#find probabilities and predictions\n",
        "with torch.no_grad():\n",
        "  outputs = model(blurred_images)\n",
        "  probabilities = torch.nn.functional.softmax(outputs, dim = 1)\n",
        "  _, blur_pred = torch.max(outputs.data, 1)\n",
        "\n",
        "\n",
        "blur_preds = blur_pred.cpu().numpy()\n",
        "blur_probs = probabilities.cpu().numpy()\n",
        "\n",
        "\n",
        "conformal_predictions = conformal_prediction(blur_probs, threshold)\n",
        "print(\"blur evaluation:\")\n",
        "evaluate_and_print(observed_labels, conformal_predictions, blur_preds, 10, 200)\n",
        "\n"
      ],
      "metadata": {
        "id": "DeSTaEoWXA4L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "282e50e4-856e-48ea-90d5-f034e336dfe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blur evaluation:\n",
            "the prediction was in the set  27.800000000000004  percent of the time\n",
            "     observed labels confromal prediction set  prediction\n",
            "10                 0                [6, 5, 2]           6\n",
            "11                 6                [5, 2, 3]           5\n",
            "12                 9                   [3, 2]           3\n",
            "13                 0                [2, 6, 5]           2\n",
            "14                 1                      [1]           1\n",
            "..               ...                      ...         ...\n",
            "195                3                [2, 3, 8]           2\n",
            "196                1                      [1]           1\n",
            "197                6                      [3]           3\n",
            "198                4                   [3, 2]           3\n",
            "199                2                      [3]           3\n",
            "\n",
            "[190 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training on blurred Images"
      ],
      "metadata": {
        "id": "fKO6EeFbrZfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model -- additional training on blurred images without calibration\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "blur_train_loader = torch.utils.data.DataLoader(dataset=mnist_train_set,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "def blur_images(image):\n",
        "  return torch.tensor(cv2.blur(images[i].numpy(), (30, 30)))\n",
        "\n",
        "\n",
        "#blur the images\n",
        "blurred_images = []\n",
        "blurred_labels = []\n",
        "\n",
        "# adding blur to every image in the training set\n",
        "with torch.no_grad():\n",
        "    for images, labels in blur_train_loader:\n",
        "        for i in range(len(images)):\n",
        "            blurred_image = blur_images(images[i])\n",
        "            blurred_images.append(blurred_image)\n",
        "            blurred_labels.append(labels[i])\n",
        "\n",
        "blurred_images = torch.stack(blurred_images)\n",
        "blurred_labels = torch.tensor(blurred_labels)\n",
        "\n",
        "\n",
        "# Create a TensorDataset and DataLoader for the blurred images\n",
        "blurred_dataset = TensorDataset(blurred_images, blurred_labels)\n",
        "blurred_train_loader = DataLoader(blurred_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "\n",
        "model.train()  # training mode\n",
        "total_step = len(blurred_train_loader)\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(blurred_train_loader):\n",
        "        # each i is a batch of 128 samples\n",
        "        images = images.to(device).view(-1, 28*28) # represent images as column vectors\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize - ALWAYS IN THIS ORDER!\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Time: {:.4f} secs'\n",
        "                   .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(), time.time() - start_time))"
      ],
      "metadata": {
        "id": "ifrZ2EUErZRA",
        "outputId": "c8bf43cb-ca6d-429d-edcb-a1242e3b47c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Step [100/375], Loss: 1.1225, Time: 0.6869 secs\n",
            "Epoch [1/1], Step [200/375], Loss: 0.7359, Time: 1.2192 secs\n",
            "Epoch [1/1], Step [300/375], Loss: 0.5970, Time: 1.7158 secs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now use original calibration (the conformal predicition with the blurry images)\n",
        "\n",
        "#creating blurry images again\n",
        "\n",
        "blur_test_loader = torch.utils.data.DataLoader(dataset=mnist_test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "def blur_images(image):\n",
        "  return torch.tensor(cv2.blur(images[i].numpy(), (30, 30)))\n",
        "\n",
        "\n",
        "#blur the images\n",
        "blurred_images = []\n",
        "blurred_labels = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in blur_test_loader:\n",
        "        for i in range(len(images)):\n",
        "            blurred_image = blur_images(images[i])\n",
        "            blurred_images.append(blurred_image)\n",
        "            blurred_labels.append(labels[i])\n",
        "\n",
        "blurred_images = torch.stack(blurred_images)\n",
        "blurred_labels = torch.tensor(blurred_labels)\n",
        "\n",
        "\n",
        "# Create a TensorDataset and DataLoader for the blurred images\n",
        "blurred_dataset = TensorDataset(blurred_images, blurred_labels)\n",
        "blur_test_loader = DataLoader(blurred_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "blur_test_preds = []\n",
        "blur_test_probs = []\n",
        "\n",
        "#testing on the blurred image with original calibration\n",
        "with torch.no_grad():\n",
        "    for images, _ in blur_test_loader:\n",
        "        images = images.to(device).view(images.size(0), -1)\n",
        "        outputs = model(images)\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim = 1) #1 corresponds to columns\n",
        "        #the prediction outputs the index of what it thinks the class is\n",
        "        #the ommited term is the value\n",
        "        _, predictions = torch.max(outputs.data, 1) #get the index of the highest output\n",
        "        # Append to lists\n",
        "        blur_test_preds.extend(predictions.cpu().numpy())\n",
        "        blur_test_probs.extend(probabilities.cpu().numpy())\n",
        "\n",
        "\n",
        "observed_labels = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in blur_test_loader:\n",
        "        observed_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "conformal_predictions = conformal_prediction(blur_test_probs, threshold)\n",
        "print(\"After putting additional training with no recalibration:\")\n",
        "evaluate_and_print(observed_labels, conformal_predictions, blur_test_preds, 100, 150)\n"
      ],
      "metadata": {
        "id": "CN6NVvwWuWUi",
        "outputId": "de797f9c-b59a-4449-8aff-2563a8b69519",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the prediction was in the set  91.02  percent of the time\n",
            "     observed labels confromal prediction set  prediction\n",
            "100                6                      [6]           6\n",
            "101                0                      [0]           0\n",
            "102                5                      [5]           5\n",
            "103                4                      [4]           4\n",
            "104                9                   [9, 5]           9\n",
            "105                9                      [9]           9\n",
            "106                2                      [0]           0\n",
            "107                1                      [1]           1\n",
            "108                9                      [9]           9\n",
            "109                4                   [9, 4]           9\n",
            "110                8                   [8, 3]           8\n",
            "111                7                      [1]           1\n",
            "112                3                [3, 1, 8]           3\n",
            "113                9                      [9]           9\n",
            "114                7                   [9, 7]           9\n",
            "115                4                      [9]           9\n",
            "116                4                   [4, 9]           4\n",
            "117                4                      [4]           4\n",
            "118                9                   [9, 4]           9\n",
            "119                2                [7, 8, 2]           7\n",
            "120                5                   [5, 8]           5\n",
            "121                4                   [6, 4]           6\n",
            "122                7                      [7]           7\n",
            "123                6                   [6, 9]           6\n",
            "124                7                      [7]           7\n",
            "125                9                      [9]           9\n",
            "126                0                      [0]           0\n",
            "127                5                      [5]           5\n",
            "128                8                      [8]           8\n",
            "129                5                      [5]           5\n",
            "130                6                      [6]           6\n",
            "131                6                      [6]           6\n",
            "132                5                   [5, 3]           5\n",
            "133                7                      [7]           7\n",
            "134                8                      [8]           8\n",
            "135                1                      [1]           1\n",
            "136                0                      [0]           0\n",
            "137                1                      [1]           1\n",
            "138                6                      [6]           6\n",
            "139                4                      [4]           4\n",
            "140                6                      [6]           6\n",
            "141                7                      [7]           7\n",
            "142                3                   [3, 7]           3\n",
            "143                1                      [1]           1\n",
            "144                7                [6, 9, 7]           6\n",
            "145                1                      [1]           1\n",
            "146                8                      [8]           8\n",
            "147                2                      [2]           2\n",
            "148                0                      [0]           0\n",
            "149                2                      [2]           2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now lets compare. lets calibrate the new blurred images\n",
        "#Calibration of the blurred images\n",
        "\n",
        "#blur everyother image in the calibration data\n",
        "\n",
        "\n",
        "mnist_cal_loader = torch.utils.data.DataLoader(dataset=mnist_cal_set,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True, drop_last=True)\n",
        "def blur_images(image):\n",
        "  return torch.tensor(cv2.blur(images[i].numpy(), (30, 30)))\n",
        "\n",
        "\n",
        "#blurs every other images\n",
        "new_cal_images = []\n",
        "new_cal_labels = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in mnist_cal_loader:\n",
        "        for i in range(len(images)):\n",
        "          if i % 2 == 0:\n",
        "            blurred_image = blur_images(images[i])\n",
        "            new_cal_images.append(blurred_image)\n",
        "            new_cal_labels.append(labels[i])\n",
        "          else:\n",
        "            new_cal_images.append(images[i])\n",
        "            new_cal_labels.append(labels[i])\n",
        "\n",
        "\n",
        "new_cal_images = torch.stack(new_cal_images)\n",
        "new_cal_labels = torch.tensor(new_cal_labels)\n",
        "\n",
        "\n",
        "# Create a TensorDataset and DataLoader for the blurred images\n",
        "new_cal_dataset = TensorDataset(new_cal_images, new_cal_labels)\n",
        "new_cal_loader = DataLoader(new_cal_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "\n",
        "#now re-calibrate\n",
        "\n",
        "new_cal_probs = []\n",
        "new_cal_preds = []\n",
        "with torch.no_grad():\n",
        "  for images, labels in new_cal_loader:\n",
        "    images = images.to(device).view(images.size(0), -1)\n",
        "    outputs = model(images)\n",
        "    #OUTPUTS IS A TENSOR with values corresponding to each image's logits (raw unnormalized scores)\n",
        "    #softmax outputs a probabiity for each class\n",
        "    probabilities = torch.nn.functional.softmax(outputs, dim = 1) #1 corresponds to columns\n",
        "    #the prediction outputs the index of what it thinks the class is\n",
        "    #the omitted term is the value\n",
        "    _, predictions = torch.max(outputs.data, 1) #get the index of the highest output\n",
        "\n",
        "    # Append to lists\n",
        "    new_cal_preds.extend(predictions.cpu().numpy())\n",
        "    new_cal_probs.extend(probabilities.cpu().numpy())\n",
        "\n",
        "new_cal_scores = []\n",
        "for prob, true_label in zip(new_cal_probs, new_cal_preds): #prob is the probability and true_label is index of pred\n",
        "  true_class_prob = prob[true_label] #the corresponding lists with their prob function getting the most predicted class\n",
        "  new_cal_scores.append(1 - true_class_prob) #s_i score\n",
        "\n",
        "new_cal_scores = np.array(new_cal_scores)\n",
        "new_sorted_scores = np.sort(new_cal_scores) #probabilities\n",
        "\n",
        "new_cal_threshold = get_quantile(new_sorted_scores, 0.05)\n",
        "print(new_cal_threshold)\n",
        "\n",
        "#now retest with new calibration on blurred images\n",
        "\n",
        "observed_labels = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in blur_test_loader:\n",
        "        observed_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "conformal_predictions = conformal_prediction(blur_test_probs, new_cal_threshold)\n",
        "print(\"After no additional training, but recalibrating with 50:50 normal to blur images:\")\n",
        "evaluate_and_print(observed_labels, conformal_predictions, blur_test_preds, 100, 150)"
      ],
      "metadata": {
        "id": "IIFTKRv_24AV",
        "outputId": "d223fbf6-4a34-4bdb-91c3-fe76cf93f420",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjusted quantile level: 0.9501008064516129\n",
            "0.6082548245787621\n",
            "the prediction was in the set  86.78  percent of the time\n",
            "     observed labels confromal prediction set  prediction\n",
            "100                6                      [6]           6\n",
            "101                0                      [0]           0\n",
            "102                5                      [5]           5\n",
            "103                4                      [4]           4\n",
            "104                9                      [9]           9\n",
            "105                9                      [9]           9\n",
            "106                2                      [0]           0\n",
            "107                1                      [1]           1\n",
            "108                9                      [9]           9\n",
            "109                4                      [9]           9\n",
            "110                8                      [8]           8\n",
            "111                7                      [1]           1\n",
            "112                3                   [3, 1]           3\n",
            "113                9                      [9]           9\n",
            "114                7                   [9, 7]           9\n",
            "115                4                      [9]           9\n",
            "116                4                      [4]           4\n",
            "117                4                      [4]           4\n",
            "118                9                      [9]           9\n",
            "119                2                   [7, 8]           7\n",
            "120                5                      [5]           5\n",
            "121                4                   [6, 4]           6\n",
            "122                7                      [7]           7\n",
            "123                6                      [6]           6\n",
            "124                7                      [7]           7\n",
            "125                9                      [9]           9\n",
            "126                0                      [0]           0\n",
            "127                5                      [5]           5\n",
            "128                8                      [8]           8\n",
            "129                5                      [5]           5\n",
            "130                6                      [6]           6\n",
            "131                6                      [6]           6\n",
            "132                5                      [5]           5\n",
            "133                7                      [7]           7\n",
            "134                8                      [8]           8\n",
            "135                1                      [1]           1\n",
            "136                0                      [0]           0\n",
            "137                1                      [1]           1\n",
            "138                6                      [6]           6\n",
            "139                4                      [4]           4\n",
            "140                6                      [6]           6\n",
            "141                7                      [7]           7\n",
            "142                3                      [3]           3\n",
            "143                1                      [1]           1\n",
            "144                7                   [6, 9]           6\n",
            "145                1                      [1]           1\n",
            "146                8                      [8]           8\n",
            "147                2                      [2]           2\n",
            "148                0                      [0]           0\n",
            "149                2                      [2]           2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yfuFjZo24R64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "\n",
        "\n",
        "rotate_loader = torch.utils.data.DataLoader(dataset=mnist_test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "observed_labels = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in mnist_test_loader:\n",
        "        observed_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "def rotate_image(image):\n",
        "    image = image.numpy().squeeze()  # Convert to numpy array and remove batch dimension\n",
        "    rows, cols = image.shape\n",
        "    rotated_image = cv2.warpAffine(image, dsize=None, M=cv2.getRotationMatrix2D((cols / 2, rows / 2), -120, 1))\n",
        "    return torch.tensor(rotated_image, dtype=torch.float32).unsqueeze(0)  # Add batch dimension back\n",
        "\n",
        "rotated_images = []\n",
        "rotated_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in mnist_test_loader:\n",
        "        for i in range(len(images)):\n",
        "            rotated_image = rotate_image(images[i])\n",
        "            rotated_images.append(rotated_image)\n",
        "            rotated_labels.append(labels[i])\n",
        "\n",
        "\n",
        "rotated_images = torch.stack(rotated_images)\n",
        "rotated_labels = torch.tensor(rotated_labels)\n",
        "\n",
        "# Evaluate the model on the rotated test set\n",
        "rotate_probs = []\n",
        "rotate_preds = []\n",
        "\n",
        "# Flatten images for model input\n",
        "rotated_images = rotated_images.view(len(rotated_images), -1).to(device)\n",
        "\n",
        "\n",
        "# Evaluate the model on the entire rotated test set at once\n",
        "with torch.no_grad():\n",
        "    outputs = model(rotated_images) #\n",
        "    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "    _, rotate_preds = torch.max(outputs.data, 1)\n",
        "\n",
        "rotate_preds = rotate_preds.cpu().numpy()\n",
        "rotate_probs = probabilities.cpu().numpy()\n",
        "\n",
        "conformal_predictions = conformal_prediction(rotate_probs, threshold)\n",
        "print(\"flip evaluation:\")\n",
        "evaluate_and_print(observed_labels, conformal_predictions, rotate_preds, 10, 200)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z694V10FhPIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "a5bba8bd-b2de-4648-c51e-9d2b2c135ed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flip evaluation:\n",
            "the prediction was in the set  23.65  percent of the time\n",
            "     observed labels confromal prediction set  prediction\n",
            "10                 0                      [0]           0\n",
            "11                 6                   [0, 8]           0\n",
            "12                 9                   [4, 3]           4\n",
            "13                 0                      [0]           0\n",
            "14                 1                      [4]           4\n",
            "..               ...                      ...         ...\n",
            "195                3                   [4, 6]           4\n",
            "196                1                      [4]           4\n",
            "197                6                      [9]           9\n",
            "198                4                      [4]           4\n",
            "199                2                      [6]           6\n",
            "\n",
            "[190 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PYXYQXhnfrmh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}