{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexisjkim/conformal_prediction_limitations/blob/main/Conformal_Prediction_Limitations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "id": "cEsZ4OIF6J7L"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, ConcatDataset, random_split\n",
        "import torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfNPe6Md7Cih",
        "outputId": "8b79e19d-e993-4413-dd09-ca057d193344"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SIZES OF DATASETS: \n",
            "training set:  48000\n",
            "calibration set:  12000\n",
            "testing set:  10000\n"
          ]
        }
      ],
      "source": [
        "# loading data and splitting into train, calibration, test sets\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "# this dataset has the training data from MNIST; will be split into training and calibration sets\n",
        "mnist_train_set = torchvision.datasets.MNIST(root='./datasets/',\n",
        "                                           train=True,\n",
        "                                           transform=torchvision.transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "\n",
        "\n",
        "# this dataset has the test data from MNIST\n",
        "mnist_test_dataset = torchvision.datasets.MNIST(root='./datasets',\n",
        "                                          train=False,\n",
        "                                          transform=torchvision.transforms.ToTensor())\n",
        "\n",
        "\n",
        "train_percentage = 0.8 # this percentage of the training data set stays in the train set; the rest becomes part of the calibration set\n",
        "\n",
        "train_size = int(train_percentage *len(mnist_train_set))\n",
        "calibration_size = len(mnist_train_set) - train_size\n",
        "\n",
        "mnist_train_set, mnist_cal_set = random_split(mnist_train_set, [train_size, calibration_size])\n",
        "\n",
        "# Data loader\n",
        "mnist_train_loader = torch.utils.data.DataLoader(dataset=mnist_train_set,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True, drop_last=True)\n",
        "\n",
        "mnist_cal_loader = torch.utils.data.DataLoader(dataset=mnist_cal_set,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True, drop_last=True)\n",
        "\n",
        "# We use drop_last=True to avoid the case where the data / batch_size != int\n",
        "\n",
        "mnist_test_loader = torch.utils.data.DataLoader(dataset=mnist_test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "print(\"SIZES OF DATASETS: \")\n",
        "print(\"training set: \", len(mnist_train_loader.dataset))\n",
        "print(\"calibration set: \", len(mnist_cal_loader.dataset))\n",
        "print(\"testing set: \", len(mnist_test_loader.dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "id": "2Be4RGKH7exA"
      },
      "outputs": [],
      "source": [
        "# class for our neural network\n",
        "\n",
        "class TwoLayerNetPiped(torch.nn.Module):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
        "        member variables.\n",
        "        Parameters:\n",
        "            D_in - dimensions of inputs\n",
        "            H - number of hidden units per layer\n",
        "            D_out - dimensions of outputs\n",
        "        \"\"\"\n",
        "        # initialzing the parent object (important!)\n",
        "        super(TwoLayerNetPiped, self).__init__()\n",
        "        # Create a pipeline - a sequence of layers\n",
        "        self.pipe = torch.nn.Sequential(\n",
        "            torch.nn.Linear(D_in, H),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(H, D_out))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        In the forward function we accept a Tensor of input data and we must return\n",
        "        a Tensor of output data. We can use Modules defined in the constructor as\n",
        "        well as arbitrary operators on Tensors.\n",
        "        Parameters:\n",
        "            x - tensor of inputs (shape: [BATCH_SIZE, D_in])\n",
        "        \"\"\"\n",
        "        return self.pipe(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "QRyTuC717Dfg"
      },
      "outputs": [],
      "source": [
        "# Setting up the model\n",
        "\n",
        "# hyper-parameters:\n",
        "num_epochs = 1\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Device configuration, as before\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# create model, send it to device\n",
        "model = TwoLayerNetPiped(D_in=28*28, H=256, D_out=10).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9plDgA17iaW",
        "outputId": "ef43a82b-2ed2-4f1e-dc26-87bd230aac45"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "\n",
        "def train_model(loader):\n",
        "\n",
        "    model.train()  # training mode\n",
        "    total_step = len(loader)\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (images, labels) in enumerate(loader):\n",
        "            # each i is a batch of 128 samples\n",
        "            images = images.to(device).view(batch_size, -1)  # represent images as column vectors\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward and optimize - ALWAYS IN THIS ORDER!\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i + 1) % 100 == 0:\n",
        "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Time: {:.4f} secs'\n",
        "                    .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(), time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/1], Step [100/375], Loss: 0.3462, Time: 0.4072 secs\n",
            "Epoch [1/1], Step [200/375], Loss: 0.2558, Time: 0.7771 secs\n",
            "Epoch [1/1], Step [300/375], Loss: 0.1883, Time: 1.1527 secs\n"
          ]
        }
      ],
      "source": [
        "train_model(mnist_train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDQWQtMs7kfL",
        "outputId": "a9120d7b-d462-4a7f-e109-f54a73419b7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 93.9 %\n"
          ]
        }
      ],
      "source": [
        "# Test the model\n",
        "\n",
        "def test_model(model, test_loader):\n",
        "\n",
        "  model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance), or use:\n",
        "  with torch.no_grad(): # \"don't keep track of the gradients\" ,can also use .detach()\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for images, labels in test_loader:\n",
        "          images = images.to(device).view(images.size(0), -1) #image.size(0) returns batch size\n",
        "          labels = labels.to(device)\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "      print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "\n",
        "test_model(model, mnist_test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_probabiliites_and_predictions(probs_list, preds_list, loader):\n",
        "    probs_list = []\n",
        "    preds_list = []\n",
        "    with torch.no_grad():\n",
        "        for images, _ in loader:\n",
        "            images = images.to(device).view(images.size(0), -1)\n",
        "            outputs = model(images)\n",
        "            probabilities = torch.nn.functional.softmax(outputs, dim = 1) #1 corresponds to columns\n",
        "            #the prediction outputs the index of what it thinks the class is\n",
        "            #the ommited term is the value\n",
        "            _, predictions = torch.max(outputs.data, 1) #get the index of the highest output\n",
        "            # Append to lists\n",
        "            preds_list.extend(predictions.cpu().numpy())\n",
        "            probs_list.extend(probabilities.cpu().numpy())\n",
        "\n",
        "    return probs_list, preds_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90lHwmd8fLIP"
      },
      "source": [
        "Conformal prediction starts here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGgyxMQzHDQl",
        "outputId": "67e93b7b-c8a1-4324-c531-57d5cd69b675"
      },
      "outputs": [],
      "source": [
        "#Calibration\n",
        "def get_cal_probs(loader):\n",
        "  cal_probs = []\n",
        "  cal_preds = []\n",
        "  cal_probs, cal_preds = get_probabiliites_and_predictions(cal_probs, cal_preds, loader)\n",
        "  print(\"cal_probs:\", cal_probs[:5])\n",
        "  print(\"cal_preds:\", cal_preds[:5])\n",
        "\n",
        "  cal_scores = []\n",
        "  for prob, true_label in zip(cal_probs, cal_preds): #prob is the probability and true_label is index of pred\n",
        "    true_class_prob = prob[true_label] #the corresponding lists with their prob function getting the most predicted class\n",
        "    cal_scores.append(1 - true_class_prob) #s_i score\n",
        "\n",
        "  cal_scores = np.array(cal_scores)\n",
        "  sorted_scores = np.sort(cal_scores) #probabilities\n",
        "\n",
        "  return sorted_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQJrZ75ZYBRP",
        "outputId": "d1afd056-fa86-44ef-f846-8f82a2dd8296"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def get_quantile(scores, alpha, loader):\n",
        "  n = 0\n",
        "  for _, labels in loader:\n",
        "    n += labels.size(0)\n",
        "    \n",
        "  q_level = math.ceil((1 - alpha) * (n + 1)) / n\n",
        "\n",
        "  print(f\"Adjusted quantile level: {q_level}\")\n",
        "  return np.percentile(scores, (1 - alpha) * 100)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cal_probs: [array([9.3085878e-04, 3.7398211e-05, 1.8736504e-03, 1.0926040e-04,\n",
            "       1.5031201e-04, 2.6068799e-03, 9.9416536e-01, 1.2302830e-05,\n",
            "       4.2266569e-05, 7.1714807e-05], dtype=float32), array([1.8455107e-02, 7.8753212e-05, 4.5731825e-01, 2.7203837e-02,\n",
            "       2.4777562e-03, 9.0805935e-03, 1.1539598e-04, 2.7062741e-01,\n",
            "       1.5590148e-02, 1.9905274e-01], dtype=float32), array([2.8487886e-05, 2.5531068e-05, 2.3621672e-03, 1.7810137e-03,\n",
            "       7.7062019e-04, 4.1201366e-03, 4.3087686e-05, 9.7918848e-07,\n",
            "       9.9034470e-01, 5.2335719e-04], dtype=float32), array([4.92926119e-07, 9.46744372e-09, 2.45024476e-05, 8.16601023e-05,\n",
            "       1.00103435e-07, 9.91209507e-01, 2.35806730e-09, 1.44923656e-10,\n",
            "       8.68356228e-03, 2.46513935e-07], dtype=float32), array([6.8132962e-05, 3.2042010e-08, 9.3226066e-05, 3.3552597e-06,\n",
            "       9.9868101e-01, 8.4813546e-05, 1.9283133e-04, 6.5558146e-05,\n",
            "       1.6285777e-04, 6.4813002e-04], dtype=float32)]\n",
            "cal_preds: [6, 2, 8, 5, 4]\n",
            "Adjusted quantile level: 0.9501008064516129\n",
            "0.44042842388153086\n"
          ]
        }
      ],
      "source": [
        "alpha = 0.05\n",
        "sorted_scores = get_cal_probs(mnist_cal_loader)\n",
        "threshold = get_quantile(sorted_scores, alpha, mnist_cal_loader) #for the calibration set\n",
        "print(threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "sPdmY-_OdGe5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "#we know the conformal prediciton model takes in probabilities until it reaches the\n",
        "#the threshold q hat\n",
        "#the threshold is q hat (that quantile value)\n",
        "\n",
        "def conformal_prediction(probabilities, threshold):\n",
        "    predictions = []\n",
        "    for prob in probabilities:\n",
        "        sorted_indices = np.argsort(prob)[::-1]\n",
        "        total = 0.0\n",
        "        prediction = []\n",
        "        for i in sorted_indices:\n",
        "            total += prob[i]\n",
        "            prediction.append(i)\n",
        "            if total > 1 - threshold: #we do 1 - threshold because we want to observe the right side as we are adding in ascending order\n",
        "                break\n",
        "        predictions.append(prediction)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "id": "KfymFHAH2Y0X"
      },
      "outputs": [],
      "source": [
        "#evaluation\n",
        "def evaluate_and_print(observed_labels, conformal_prediction, predicted, start_row, end_row):\n",
        "  formatted_output = pd.DataFrame({\n",
        "    'observed labels': observed_labels,\n",
        "    'confromal prediction set': conformal_prediction,\n",
        "    'prediction': predicted\n",
        "  })\n",
        "\n",
        "\n",
        "  #evaluation metric\n",
        "  hits = 0\n",
        "  total = len(observed_labels)\n",
        "  for i in range(len(observed_labels)):\n",
        "    conf_pred_row = conformal_prediction[i]\n",
        "    observed = observed_labels[i]\n",
        "\n",
        "    if observed in conf_pred_row:\n",
        "      hits += 1\n",
        "\n",
        "  print(\"the prediction was in the set \", hits/total *100, \" percent of the time\")\n",
        "\n",
        "  print(formatted_output[start_row:end_row])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {},
      "outputs": [],
      "source": [
        "#getting observed label functions\n",
        "def get_observed_labels(loader):\n",
        "    observed_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            observed_labels.extend(labels.cpu().numpy())\n",
        "    return observed_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJ9v7D221CeL",
        "outputId": "fc805388-e12e-41f8-b3a1-e5e198375a04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The conformal prediction accuracy based on training data and testing data from the same distribution is:\n",
            "the prediction was in the set  95.53  percent of the time\n",
            "     observed labels confromal prediction set  prediction\n",
            "300                4                   [6, 1]           6\n",
            "301                7                      [7]           7\n",
            "302                1                      [1]           1\n",
            "303                2                      [2]           2\n",
            "304                4                      [4]           4\n",
            "..               ...                      ...         ...\n",
            "445                6                      [0]           0\n",
            "446                6                      [6]           6\n",
            "447                4                      [4]           4\n",
            "448                9                   [8, 9]           8\n",
            "449                3                      [3]           3\n",
            "\n",
            "[150 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "#evaluating our testing data set\n",
        "\n",
        "test_observed_labels = get_observed_labels(mnist_test_loader)\n",
        "\n",
        "test_probs = []\n",
        "test_preds = []\n",
        "test_probs, test_preds = get_probabiliites_and_predictions(test_probs, test_preds, mnist_test_loader)\n",
        "\n",
        "\n",
        "conformal_predictions = conformal_prediction(test_probs, threshold)\n",
        "print(\"The conformal prediction accuracy based on training data and testing data from the same distribution is:\")\n",
        "evaluate_and_print(test_observed_labels, conformal_predictions, test_preds, 300, 450)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jvpco2U-XE1R"
      },
      "source": [
        "Repeating the experiment with test data that doesn't match the calibration set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model -- additional training on blurred images without calibration\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Functions for Blurring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {},
      "outputs": [],
      "source": [
        "def blur_images(image):\n",
        "  return torch.tensor(cv2.blur(image.numpy(), (30, 30)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {},
      "outputs": [],
      "source": [
        "#get blurred data\n",
        "#blur the images\n",
        "def get_blurred_data(loader):\n",
        "    blurred_images = []\n",
        "    blurred_labels = []\n",
        "\n",
        "    # adding blur to every image in the training set\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            for i in range(len(images)):\n",
        "                blurred_image = blur_images(images[i])\n",
        "                blurred_images.append(blurred_image)\n",
        "                blurred_labels.append(labels[i])\n",
        "\n",
        "    blurred_images = torch.stack(blurred_images)\n",
        "    blurred_labels = torch.tensor(blurred_labels)\n",
        "\n",
        "    return blurred_images, blurred_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_blur_loader(blurred_images, blurred_labels):\n",
        "    # Create a TensorDataset and DataLoader for the blurred images\n",
        "    blurred_dataset = TensorDataset(blurred_images, blurred_labels)\n",
        "    blurred_loader = DataLoader(blurred_dataset, batch_size=128, shuffle=False)\n",
        "    return blurred_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeSTaEoWXA4L",
        "outputId": "282e50e4-856e-48ea-90d5-f034e336dfe4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is the conformal prediction accuracy based on training data and testing data from different distributions. \n",
            "The training data contains normal images while the testing data were all blurred:\n",
            "the prediction was in the set  23.09  percent of the time\n",
            "     observed labels confromal prediction set  prediction\n",
            "10                 0                [2, 5, 3]           2\n",
            "11                 6                [5, 3, 2]           5\n",
            "12                 9                      [3]           3\n",
            "13                 0                [2, 3, 5]           2\n",
            "14                 1                      [1]           1\n",
            "..               ...                      ...         ...\n",
            "195                3                [2, 3, 5]           2\n",
            "196                1                      [1]           1\n",
            "197                6                      [3]           3\n",
            "198                4                   [3, 7]           3\n",
            "199                2                      [3]           3\n",
            "\n",
            "[190 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "#testing our model on blurred images\n",
        "\n",
        "blur_loader = torch.utils.data.DataLoader(dataset=mnist_test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "\n",
        "observed_labels = get_observed_labels(blur_loader)\n",
        "\n",
        "blurred_images, blurred_labels = get_blurred_data(blur_loader)\n",
        "blurred_loader = create_blur_loader(blurred_images, blurred_labels)\n",
        "blur_probs = []\n",
        "blur_preds = []\n",
        "blur_probs, blur_preds = get_probabiliites_and_predictions(blur_probs, blur_preds, blurred_loader)\n",
        "'''''\n",
        "blur_probs = []\n",
        "blur_pred = []\n",
        "\n",
        "# Flatten images for model input\n",
        "blurred_images = blurred_images.view(len(blurred_images), -1).to(device)\n",
        "\n",
        "#find probabilities and predictions\n",
        "with torch.no_grad():\n",
        "  outputs = model(blurred_images)\n",
        "  probabilities = torch.nn.functional.softmax(outputs, dim = 1)\n",
        "  _, blur_pred = torch.max(outputs.data, 1)\n",
        "\n",
        "\n",
        "blur_preds = blur_pred.cpu().numpy()\n",
        "blur_probs = probabilities.cpu().numpy()'''\n",
        "\n",
        "\n",
        "conformal_predictions = conformal_prediction(blur_probs, threshold)\n",
        "print(\"This is the conformal prediction accuracy based on training data and testing data from different distributions. \\nThe training data contains normal images while the testing data were all blurred:\")\n",
        "evaluate_and_print(observed_labels, conformal_predictions, blur_preds, 10, 200)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKO6EeFbrZfP"
      },
      "source": [
        "Training on blurred Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifrZ2EUErZRA",
        "outputId": "c8bf43cb-ca6d-429d-edcb-a1242e3b47c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/1], Step [100/375], Loss: 1.0233, Time: 0.1720 secs\n",
            "Epoch [1/1], Step [200/375], Loss: 0.8217, Time: 0.2688 secs\n",
            "Epoch [1/1], Step [300/375], Loss: 0.5997, Time: 0.3676 secs\n"
          ]
        }
      ],
      "source": [
        "# Train the model -- additional training on blurred images without calibration\n",
        "\n",
        "\n",
        "blurred_train_loader = torch.utils.data.DataLoader(dataset=mnist_train_set,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "\n",
        "observed_labels = get_observed_labels(blurred_train_loader)\n",
        "\n",
        "blurred_images, blurred_labels = get_blurred_data(blurred_train_loader)\n",
        "blurred_train_loader = create_blur_loader(blurred_images, blurred_labels)\n",
        "blur_train_probs = []\n",
        "blur_train_preds = []\n",
        "blur_probs, blur_preds = get_probabiliites_and_predictions(blur_train_probs, blur_train_preds, blurred_train_loader)\n",
        "\n",
        "\n",
        "train_model(blurred_train_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN6NVvwWuWUi",
        "outputId": "de797f9c-b59a-4449-8aff-2563a8b69519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After putting additional training with blurred images with no recalibration:\n",
            "the prediction was in the set  89.92  percent of the time\n",
            "     observed labels confromal prediction set  prediction\n",
            "100                6                      [6]           6\n",
            "101                0                      [0]           0\n",
            "102                5                      [5]           5\n",
            "103                4                      [4]           4\n",
            "104                9                      [9]           9\n",
            "105                9                      [9]           9\n",
            "106                2                      [0]           0\n",
            "107                1                      [1]           1\n",
            "108                9                      [9]           9\n",
            "109                4                   [9, 4]           9\n",
            "110                8                   [8, 3]           8\n",
            "111                7                   [1, 7]           1\n",
            "112                3                [3, 5, 6]           3\n",
            "113                9                      [9]           9\n",
            "114                7                [9, 6, 7]           9\n",
            "115                4                      [9]           9\n",
            "116                4                      [4]           4\n",
            "117                4                      [4]           4\n",
            "118                9                   [9, 4]           9\n",
            "119                2                   [2, 7]           2\n",
            "120                5                   [5, 8]           5\n",
            "121                4                      [6]           6\n",
            "122                7                   [7, 4]           7\n",
            "123                6                      [6]           6\n",
            "124                7                      [7]           7\n",
            "125                9                      [9]           9\n",
            "126                0                      [0]           0\n",
            "127                5                      [5]           5\n",
            "128                8                      [8]           8\n",
            "129                5                      [5]           5\n",
            "130                6                      [6]           6\n",
            "131                6                      [6]           6\n",
            "132                5                   [5, 3]           5\n",
            "133                7                   [7, 2]           7\n",
            "134                8                      [8]           8\n",
            "135                1                      [1]           1\n",
            "136                0                      [0]           0\n",
            "137                1                      [1]           1\n",
            "138                6                      [6]           6\n",
            "139                4                      [4]           4\n",
            "140                6                      [6]           6\n",
            "141                7                      [7]           7\n",
            "142                3                   [3, 2]           3\n",
            "143                1                      [1]           1\n",
            "144                7                   [6, 9]           6\n",
            "145                1                      [1]           1\n",
            "146                8                   [8, 9]           8\n",
            "147                2                      [2]           2\n",
            "148                0                      [0]           0\n",
            "149                2                      [2]           2\n"
          ]
        }
      ],
      "source": [
        "#now use original calibration (the conformal predicition with the blurry images)\n",
        "\n",
        "#creating blurry images again\n",
        "\n",
        "blur_test_loader = torch.utils.data.DataLoader(dataset=mnist_test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "observed_labels = get_observed_labels(blur_test_loader)\n",
        "\n",
        "blurred_images, blurred_labels = get_blurred_data(blur_test_loader)\n",
        "blurred_test_loader = create_blur_loader(blurred_images, blurred_labels)\n",
        "\n",
        "\n",
        "blur_test_preds = []\n",
        "blur_test_probs = []\n",
        "\n",
        "blur_test_probs, blur_test_preds = get_probabiliites_and_predictions(blur_test_probs, blur_test_preds, blurred_test_loader)\n",
        "\n",
        "\n",
        "conformal_predictions = conformal_prediction(blur_test_probs, threshold)\n",
        "print(\"After putting additional training with blurred images with no recalibration:\")\n",
        "evaluate_and_print(observed_labels, conformal_predictions, blur_test_preds, 100, 150)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIFTKRv_24AV",
        "outputId": "d223fbf6-4a34-4bdb-91c3-fe76cf93f420"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cal_probs: [array([2.1286048e-03, 1.8863025e-04, 1.1733644e-02, 7.7244453e-03,\n",
            "       2.2128671e-01, 6.8366039e-03, 2.5394693e-02, 2.1462882e-02,\n",
            "       1.0846730e-02, 6.9239700e-01], dtype=float32), array([1.59335032e-03, 2.57829106e-05, 8.73623312e-01, 1.22923955e-01,\n",
            "       3.75307234e-13, 3.72674986e-04, 4.96868857e-08, 9.28163900e-07,\n",
            "       1.45993195e-03, 7.50253071e-12], dtype=float32), array([3.8844727e-02, 6.6245675e-01, 1.5717421e-01, 1.7904196e-02,\n",
            "       4.5091906e-03, 5.2619702e-04, 1.5082151e-02, 3.7710045e-02,\n",
            "       4.9831405e-02, 1.5961099e-02], dtype=float32), array([9.9998331e-01, 5.6166445e-09, 9.4805796e-07, 9.4981125e-08,\n",
            "       2.6232028e-15, 1.5659100e-05, 2.3029896e-11, 3.8846411e-09,\n",
            "       1.1626632e-08, 2.0920380e-15], dtype=float32), array([0.00490593, 0.00654617, 0.01403603, 0.03789134, 0.00795527,\n",
            "       0.03962396, 0.12203734, 0.00978187, 0.6152176 , 0.14200442],\n",
            "      dtype=float32)]\n",
            "cal_preds: [9, 2, 1, 0, 8]\n",
            "Adjusted quantile level: 0.9501008064516129\n",
            "0.6076521888375283\n",
            "After putting additional training with blurred images with no recalibration:\n",
            "the prediction was in the set  85.74000000000001  percent of the time\n",
            "     observed labels confromal prediction set  prediction\n",
            "100                6                      [6]           6\n",
            "101                0                      [0]           0\n",
            "102                5                      [5]           5\n",
            "103                4                      [4]           4\n",
            "104                9                      [9]           9\n",
            "105                9                      [9]           9\n",
            "106                2                      [0]           0\n",
            "107                1                      [1]           1\n",
            "108                9                      [9]           9\n",
            "109                4                      [9]           9\n",
            "110                8                      [8]           8\n",
            "111                7                      [1]           1\n",
            "112                3                   [3, 5]           3\n",
            "113                9                      [9]           9\n",
            "114                7                   [9, 6]           9\n",
            "115                4                      [9]           9\n",
            "116                4                      [4]           4\n",
            "117                4                      [4]           4\n",
            "118                9                      [9]           9\n",
            "119                2                      [2]           2\n",
            "120                5                   [5, 8]           5\n",
            "121                4                      [6]           6\n",
            "122                7                      [7]           7\n",
            "123                6                      [6]           6\n",
            "124                7                      [7]           7\n",
            "125                9                      [9]           9\n",
            "126                0                      [0]           0\n",
            "127                5                      [5]           5\n",
            "128                8                      [8]           8\n",
            "129                5                      [5]           5\n",
            "130                6                      [6]           6\n",
            "131                6                      [6]           6\n",
            "132                5                   [5, 3]           5\n",
            "133                7                      [7]           7\n",
            "134                8                      [8]           8\n",
            "135                1                      [1]           1\n",
            "136                0                      [0]           0\n",
            "137                1                      [1]           1\n",
            "138                6                      [6]           6\n",
            "139                4                      [4]           4\n",
            "140                6                      [6]           6\n",
            "141                7                      [7]           7\n",
            "142                3                      [3]           3\n",
            "143                1                      [1]           1\n",
            "144                7                      [6]           6\n",
            "145                1                      [1]           1\n",
            "146                8                      [8]           8\n",
            "147                2                      [2]           2\n",
            "148                0                      [0]           0\n",
            "149                2                      [2]           2\n"
          ]
        }
      ],
      "source": [
        "#Now lets compare. lets calibrate the new blurred images\n",
        "#Calibration of the blurred images\n",
        "\n",
        "#blur everyother image in the calibration data\n",
        "\n",
        "\n",
        "mnist_cal_loader = torch.utils.data.DataLoader(dataset=mnist_cal_set,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True, drop_last=True)\n",
        "\n",
        "\n",
        "#blurs every other images\n",
        "new_cal_images = []\n",
        "new_cal_labels = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in mnist_cal_loader:\n",
        "        for i in range(len(images)):\n",
        "          if i % 2 == 0:\n",
        "            blurred_image = blur_images(images[i])\n",
        "            new_cal_images.append(blurred_image)\n",
        "            new_cal_labels.append(labels[i])\n",
        "          else:\n",
        "            new_cal_images.append(images[i])\n",
        "            new_cal_labels.append(labels[i])\n",
        "\n",
        "\n",
        "new_cal_images = torch.stack(new_cal_images)\n",
        "new_cal_labels = torch.tensor(new_cal_labels)\n",
        "\n",
        "new_cal_loader = create_blur_loader(new_cal_images, new_cal_labels)\n",
        "\n",
        "new_cal_observed_labels = get_observed_labels(new_cal_loader)\n",
        "\n",
        "alpha = 0.05\n",
        "sorted_scores = get_cal_probs(new_cal_loader)\n",
        "new_cal_threshold = get_quantile(sorted_scores, alpha, new_cal_loader) #for the calibration set\n",
        "print(new_cal_threshold)\n",
        "\n",
        "#after calibrating get the accuracy\n",
        "# we calibratted on 50:50 now we want to test on all blurred images\n",
        "\n",
        "conformal_predictions = conformal_prediction(blur_test_probs, new_cal_threshold)\n",
        "print(\"After putting additional training with blurred images with no recalibration:\")\n",
        "evaluate_and_print(observed_labels, conformal_predictions, blur_test_preds, 100, 150)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfuFjZo24R64"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The conformal prediction accuracy based on training data and testing data from the same distribution is:\n",
            "the prediction was in the set  94.12  percent of the time\n",
            "     observed labels confromal prediction set  prediction\n",
            "300                4                      [6]           6\n",
            "301                7                      [7]           7\n",
            "302                1                      [1]           1\n",
            "303                2                      [2]           2\n",
            "304                4                      [4]           4\n",
            "..               ...                      ...         ...\n",
            "445                6                      [0]           0\n",
            "446                6                      [6]           6\n",
            "447                4                      [4]           4\n",
            "448                9                      [8]           8\n",
            "449                3                      [3]           3\n",
            "\n",
            "[150 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "#sanity check -- what happens if you test with all non-bluured images with 50:50 calibration\n",
        "test_observed_labels = get_observed_labels(mnist_test_loader)\n",
        "new_cal_normal_conformal_predictions = conformal_prediction(test_probs, new_cal_threshold)\n",
        "print(\"The conformal prediction accuracy based on training data and testing data from the same distribution is:\")\n",
        "evaluate_and_print(test_observed_labels, new_cal_normal_conformal_predictions, test_preds, 300, 450)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "z694V10FhPIR",
        "outputId": "a5bba8bd-b2de-4648-c51e-9d2b2c135ed0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "flip evaluation:\n",
            "the prediction was in the set  23.65  percent of the time\n",
            "     observed labels confromal prediction set  prediction\n",
            "10                 0                      [0]           0\n",
            "11                 6                   [0, 8]           0\n",
            "12                 9                   [4, 3]           4\n",
            "13                 0                      [0]           0\n",
            "14                 1                      [4]           4\n",
            "..               ...                      ...         ...\n",
            "195                3                   [4, 6]           4\n",
            "196                1                      [4]           4\n",
            "197                6                      [9]           9\n",
            "198                4                      [4]           4\n",
            "199                2                      [6]           6\n",
            "\n",
            "[190 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "'''''import cv2\n",
        "\n",
        "\n",
        "\n",
        "rotate_loader = torch.utils.data.DataLoader(dataset=mnist_test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "observed_labels = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in mnist_test_loader:\n",
        "        observed_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "def rotate_image(image):\n",
        "    image = image.numpy().squeeze()  # Convert to numpy array and remove batch dimension\n",
        "    rows, cols = image.shape\n",
        "    rotated_image = cv2.warpAffine(image, dsize=None, M=cv2.getRotationMatrix2D((cols / 2, rows / 2), -120, 1))\n",
        "    return torch.tensor(rotated_image, dtype=torch.float32).unsqueeze(0)  # Add batch dimension back\n",
        "\n",
        "rotated_images = []\n",
        "rotated_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in mnist_test_loader:\n",
        "        for i in range(len(images)):\n",
        "            rotated_image = rotate_image(images[i])\n",
        "            rotated_images.append(rotated_image)\n",
        "            rotated_labels.append(labels[i])\n",
        "\n",
        "\n",
        "rotated_images = torch.stack(rotated_images)\n",
        "rotated_labels = torch.tensor(rotated_labels)\n",
        "\n",
        "# Evaluate the model on the rotated test set\n",
        "rotate_probs = []\n",
        "rotate_preds = []\n",
        "\n",
        "# Flatten images for model input\n",
        "rotated_images = rotated_images.view(len(rotated_images), -1).to(device)\n",
        "\n",
        "\n",
        "# Evaluate the model on the entire rotated test set at once\n",
        "with torch.no_grad():\n",
        "    outputs = model(rotated_images) #\n",
        "    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "    _, rotate_preds = torch.max(outputs.data, 1)\n",
        "\n",
        "rotate_preds = rotate_preds.cpu().numpy()\n",
        "rotate_probs = probabilities.cpu().numpy()\n",
        "\n",
        "conformal_predictions = conformal_prediction(rotate_probs, threshold)\n",
        "print(\"flip evaluation:\")\n",
        "evaluate_and_print(observed_labels, conformal_predictions, rotate_preds, 10, 200)\n",
        "\n",
        "'''''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYXYQXhnfrmh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
